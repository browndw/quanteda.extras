---
title: "Introduction to keyness functions in the quanteda.extras R package"
author: "David Brown"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{keyness_introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

## Load the quanteda.extras package

Load the package, as well as others that we'll use in this vignette.

```{r setup, message = FALSE, error=FALSE, warning=FALSE}
library(quanteda.extras)
library(quanteda)
library(tidyverse)
```

## Prepare the data

## Prepare the data

First, we'll use to **preprocess_text( )** function to "clean" the text data. See the **preprocess vignette** for more information.

```{r data_prep, message = FALSE, error=FALSE}
sc <- sample_corpus %>%
  mutate(text = preprocess_text(text))
```

Next, we'll subset the data and create two sub-copora: one of fiction texts and one of academic.

```{r subset, message = FALSE, error=FALSE, warning=FALSE}
sc_fict <- sc %>%
  filter(str_detect(doc_id, "fic")) %>% # select the texts
  corpus() %>% # create a corpus object
  tokens(what="fastestword", remove_numbers=TRUE) %>% # tokenize
  dfm() # create a document-feature matrix (dfm)

sc_acad <- sc %>%
  filter(str_detect(doc_id, "acad")) %>% # select the texts
  corpus() %>% # create a corpus object
  tokens(what="fastestword", remove_numbers=TRUE) %>% # tokenize
  dfm() # create a document-feature matrix (dfm)
```

There are a couple of important issues to be aware of:

1. The **quanteda** package has it's own native keyness function as part of  [**quanteda.textstats**](https://cran.r-project.org/web/packages/quanteda.textstats/index.html): **textstat_keyness( )**.
1. Using the **textstat_keyness( )** function requires a slightly different workflow, but is perfectly fine if you only want to generate a basic keyness statistic.
1. The keyness functions here expand that basic functionality by adding effect sizes and other measures, as well as an implementation of **"key key words,"** which accounts for how distributed key words are in the target corpus.

## Generate a keyness table

The **keyness_table( )** takes a target and a reference **dfm**. You can also apply the ["Yates correction"](https://influentialpoints.com/Training/g-likelihood_ratio_test.htm) by setting **yates=TRUE**.

```{r keyness, message = FALSE, error=FALSE, warning=FALSE}
kt <- keyness_table(sc_fict, sc_acad)
```

We can look at the first few rows of the table:

```{r echo=FALSE}
knitr::kable(head(kt))
```

The columns are as follows:

1. **LL**: the keyness value or [**log-likelihood**](http://ucrel.lancs.ac.uk/llwizard.html), also know as a G2 or goodness-of-fit test.
1. **LR**: the effect size, which here is the [**log ratio**](http://cass.lancs.ac.uk/log-ratio-an-informal-introduction/)
1. **PV**: the *p*-value associated with the log-likelihood
1. **AF_Tar**: the absolute frequency in the target corpus
1. **AF_Ref**: the absolute frequency in the reference corpus
1. **Per_10.x_Tar**: the relatvie frequency in the target corpus (automatically calibrated to a normaizing factor, where here is per 100,000 tokens)
1. **Per_10.x_Ref**: the relatvie frequency in the reference corpus (automatically calibrated to a normaizing factor, where here is per 100,000 tokens)
1. **DP_Tar**: the [deviation of proportions](https://www.researchgate.net/publication/233685362_Dispersions_and_adjusted_frequencies_in_corpora) (a dispersion measure) in the target corpus
1. **DP_Ref**: the deviation of proportions in the reference corpus

## Key key words

The concept of ["**key key words**"](https://lexically.net/downloads/version5/HTML/index.html?keykeyness_definition.htm) was introduced by Mike Smith for the WordSmith concordancer. The process comparares each text in the target corpus to the reference corpus. Log-likelihood is calculated for each comparision. Then a mean is calculated for keyness and effect size. In addition, a range is provided for the number of texts in which keyness reaches signficance for a given threshold. (The default is *p* < 0.05.) That range is returned as a percentage.

In this way, **key key words** accounts for the dispersion of key words by indicating whether a keyness value is driven by a relatively high frequency in a few target texts or many.

```{r key_keys, message = FALSE, error=FALSE, warning=FALSE}
kk <- key_keys(sc_fict, sc_acad)
```

Again, we can look at the first few rows of the table:

```{r echo=FALSE}
knitr::kable(head(kk))
```

## Keyness pairs

There is also a function for quickly generating pair-wise keyness comparisions among multiple sub-corpora. To demonstrate, create a third **dfm**, this time containing news articles.

```{r}
sc_news <- sc %>%
  filter(str_detect(doc_id, "news")) %>% # select the texts
  corpus() %>% # create a corpus object
  tokens(what="fastestword", remove_numbers=TRUE) %>% # tokenize
  dfm() # create a document-feature matrix (dfm)
```

To produce a data.frame comparing more than two sup-corpora, use the **keyness_pairs( )** function:

```{r key_pairs, message = FALSE, error=FALSE, warning=FALSE}
kp <- keyness_pairs(sc_news, sc_acad, sc_fict)
```

Check the result:

```{r echo=FALSE}
knitr::kable(head(kp))
```

