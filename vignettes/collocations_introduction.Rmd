---
title: "Introduction to collocation functions in the quanteda.extras R package"
author: "David Brown"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{collocations_introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

## Load the quanteda.extras package

Load the package, as well as others that we'll use in this vignette.

```{r setup, message = FALSE, error=FALSE, warning=FALSE}
library(quanteda.extras)
library(quanteda)
library(tidyverse)
library(ggraph)
```

## Prepare the data

Let's begin by preparing the data that comes with the package -- the **sample_corpus**. The corpus contains data from 8 text-types:

* Academic
* Blog
* Fiction
* Magazine
* News
* Spoken
* Television & Movie
* Web

In this way, it resembles the [Corpus of Contemporary American English](https://www.english-corpora.org/coca/). However, it contains only 50 texts from each type, and each text is only about 2,500 words. Thus, it is similar to the [Brown family of corpora](https://www1.essex.ac.uk/linguistics/external/clmt/w3c/corpus_ling/content/corpora/list/private/brown/brown.html) in its size (roughly 1 million words).

Note that this data is included *only* for demonstration purposes. It was *not* compiled to be used for research.

First, we'll use to **preprocess_text( )** function to "clean" the text data. The  **preprocess_text( )** function takes the following logical (TRUE/FALSE) arguments:

* **contractions** (if set to TRUE contractions will be separated so that, for example, *can't* becomes *ca n't*)
* **hyphens** (if set to TRUE hyphens will be replaced by spaces)
* **punctuation** (if set to TRUE all punctuation marks will be exluded)
* **lower_case** (if set to TRUE all strings are converted to lower case)
* **accent_replace** (if set to TRUE accented chacaracters will be replaced by unaccented ones)
* **letters_only** (if set to TRUE strings including non-letters will be eliminated)

```{r data_prep, message = FALSE, error=FALSE}
sc <- sample_corpus %>%
  mutate(text = preprocess_text(text))
```

Next, create a corpus and tokenize the data:

```{r tokens}
sc_tokens <- sc %>%
  corpus() %>% # create a corpus object
  tokens(what="fastestword", remove_numbers=TRUE) # tokenize the data
```

## Collocates by mutual information

The **collocates_by_MI( )** function produces collocation measures (by pointwise mutual information) for a specified token in a **quanteda tokens** object. In addition to a token, a span or window (as given by a number of words to the **left** and **right** of the **node word**) is required. The default is 5 to the left and 5 to the right.

```{r}
time_collocations <- collocates_by_MI(brown_tkns, "time")
money_collocations <- collocates_by_MI(brown_tkns, "money")

tc <- time_collocations %>% filter(col_freq >= 5 & MI_1 >= 5)
mc <- money_collocations %>% filter(col_freq >= 5 & MI_1 >= 5)
```

```{r}
net <- col_network(tc, mc)
```

```{r}
ggraph(net, weight = link_weight, layout = "stress") + 
  geom_edge_link(color = "gray80", alpha = .75) + 
  geom_node_point(aes(alpha = node_weight, size = 3, color = n_intersects)) +
  geom_node_text(aes(label = label), repel = T) +
  scale_alpha(range = c(0.2, 0.9)) +
  theme_graph() +
  theme(legend.position="none")
```

